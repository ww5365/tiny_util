[TOC]

# ES相关知识总结

## ES基本命令

* 创建索引
PUT https://10.33.236.11:9210/索引名

PUT https://10.33.236.11:9210/ww_test


* 创建文档
POST https://10.32.231.48:9212/ww_test/_doc

```json
说明：如果没有创建mapping，es会自动创建
 { 
 	"title":"小米手机", 
 	"category":"小米", 
 	"images":"http://www.gulixueyuan.com/xm.jpg", 
 	"price":3999.00 
 }
```

* 查看创建的文档

GET https://10.32.231.48:9212/ww_test/_doc/文档ID

https://10.32.231.48:9212/ww_test/_doc/AMyX23wBSgsiA9urx1LC


* 删除文档
DELETE https://10.32.231.48:9212/ww_test/_doc/AMyX23wBSgsiA9urx1LC

删除这个，软删除


* 创建mapping

PUT https://10.32.231.48:9212/ww_test/_mapping

``` json
{
 "properties": {
 "name":{
 "type": "text",
 "index": true
 },
 "sex":{
 "type": "text",
 "index": false
 },
 "age":{
 "type": "long",
 "index": false
 }
 }
}

```
```
说明如下：

- 字段名：任意填写，下面指定许多属性，例如：title、subtitle、images、price 
- type：类型，Elasticsearch 中支持的数据类型非常丰富：
  - String 类型，又分两种： 
    - text：可分词
    - keyword：不可分词，数据会作为完整字段进行匹配 
  - Numerical：数值类型，分两类：
    - 基本数据类型：long、integer、short、byte、double、float、half_float
    - 浮点数的高精度类型：scaled_float 
  - Date：日期类型 
  - Array：数组类型 
  - Object：对象 
- index：是否索引，默认为 true，也就是说你不进行任何配置，所有字段都会被索引。
  - true：字段会被索引，则可以用来进行搜索
  - false：字段不会被索引，不能用来搜索 
- store：是否将数据进行独立存储，默认为 false 
  - 原始的文本会存储在\_source 里面，默认情况下其他提取出来的字段都不是独立存储 的，是从\_source 里面提取出来的。当然你也可以独立的存储某个字段，只要设置 "store": true 即可，获取独立存储的字段要比从\_source 中解析快得多，但是也会占用 更多的空间，所以要根据实际业务需求来设置。 
- analyzer：分词器，参见analyzer章节

mapping后面可以新增加字段，已设定的不能修改；如果要修改，需要重新索引一遍，reindex.
```

* 查看索引的setting和mapping
GET https://10.33.236.11:9210/suggest_geo_guonei    // 直接用索引名，就可以得到这个索引的相关配置：setting，mapping，别名等
GET https://10.33.236.11:9210/suggest_geo_guonei/_mapping

* 查看索引所有的索引
GET https://10.33.236.11:9210/_cat/indices? 

* 查看索引中全部数据：
GET https://10.33.236.11:9210/suggest_test_3/_search

* 查看分词器的分词效果

  GET https://10.33.236.11:9210/suggest_geo_guonei/_analyze

``` json
{
    "analyzer":"text_prefix_analyzer",  # 使用这个分词器
    "text": "xunleibujiyaer"  # 对这段文件进行分词
}
```

分词器的设置：
``` json
    "analysis": {
      "analyzer": {
        "text_prefix_analyzer": {
          "type": "custom",
          "tokenizer": "text_edge_ngram_tokenizer",
          "filter": [
            "lowercase",
            "asciifolding",
            "arabic_normalization"
          ]
        }
      },
      "tokenizer": {
        "text_edge_ngram_tokenizer": {
          "type": "edge_ngram",
          "min_gram": 1,
          "max_gram": 256,
          "token_chars": [
            "letter",
            "digit"
          ]
        }
      }
    },

```

* 查看DSL的打分情况 -- explain


``` json
{
  "query"（query）: { 
    "bool"（复合语句）: { 
      "must"（复合语句参数）: [
        { "match"（子查询）: { "title":   "Search"        }},
        { "match"（子查询）: { "content": "Elasticsearch" }}
      ],
      "filter"（复合语句参数）: [ 
        { "term"（子查询）:  { "status": "published" }},
        { "range"（子查询）: { "publish_date": { "gte": "2015-01-01" }}}
      ]
    }
  },
  "explain":true
}

```



---

## 模板-template

模板用处：设置一个通用的mapping模板，当满足匹配规则时，ES自动创建满足条件的mapping。

* 创建模板和别名

```json
PUT _template/logs_template
{
      "index_patterns": "logs-*",
      "order": 1, 
      "settings": {
        "number_of_shards": 4,
        "number_of_replicas": 1
      },
      "mappings": { 
        "properties": {
          "@timestamp": {
            "type": "date"
          }
        }
      },
      "aliases": {
        "{index}-alias" : {}
      }
}

```

* 查询模板

    GET /_template/template_1,template_2
    GET /_template/temp*
    GET /_template



---




```json

    "properties": {
      "name": {
        "type": "nested",
        "properties": {
          "text": {
            "type": "text",
            "store": true,
            "index": true,
            "analyzer": "text_prefix_analyzer",  # 指定创建索引时的分词器
            "search_analyzer": "simple"  # 对查询语句使用的分词器
          }
        }
       }
     }

```



