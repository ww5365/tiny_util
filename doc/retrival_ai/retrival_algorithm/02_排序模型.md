
# 排序模型

cart -> gdbt -> Gbrank  landmart  -> deepFM

xgboost

lightGBM


## 排序特征

### 文本相关特征

CQR

OFFSET

edit distance

lcs

euclidean distance

cosine similarity

jaccard similarity

Pearson

tf-idf

bm25

### 点击特征

CTR

用户需求分布



### 深度特征

NN： 



## 排序模型

### lambdaMart

重点参考下这篇博文：

http://www.yinkuiwang.cn/2021/12/11/LambdaMart%E5%8E%9F%E7%90%86%E5%8F%8A%E5%AE%9E%E7%8E%B0/

代码：
https://github.com/jiangnanboy/learning_to_rank

https://everdark.github.io/k9/notebooks/ml/learning_to_rank/learning_to_rank.html

一句话点评：

将评价指标,比如NDCG引入到损失函数， 不可导的指标函数构构造可到的实现； 通过lamda来控制下一轮迭代的大小和方向。

牛顿法进行损失函数最优解的求解

1. https://blog.csdn.net/wuzhongqiang/article/details/110521519





### 损失函数类型 

支持gbrank loss、lambdamart dcg loss、lambdamart ndcg loss及regression loss类型。[出自链接](https://www.alibabacloud.com/help/zh/machine-learning-platform-for-ai/latest/gbdt-regression)









## reference

算法知识点——（5）集成算法—GBDT详解  : https://blog.csdn.net/Lynqwest/article/details/101540952

GBDT C++ 实现代码：https://github.com/yarny/gbdt  
    GBDT implements various pointwise, pairwise, listingwis loss functions including mse, logloss, huberized hinge loss, pairwise logloss, GBRank and LambdaMart. It supports easily addition of your own custom loss functions.

Learning to Rank算法学习之GBRank: https://www.biaodianfu.com/gbrank.html

GBrank 代码： https://github.com/szdr/my-gbrank  

GBRank的问题列表 ： https://daimajiaoliu.com/daima/47dd2271c9003fc

gbrank排序为什么会造成预测值为负的原因 : https://blog.csdn.net/a1066196847/article/details/83382708

[搜索排序算法] (https://octopuscoder.github.io/2020/01/19/%E6%90%9C%E7%B4%A2%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/)  
    LambdaRank，基于xgboost实现，参考：https://github.com/dmlc/xgboost/tree/master/demo/rank
    LambdaMART，基于LightGBM实现，参考：https://github.com/jiangnanboy/learning_to_rank
    Wide&Deep基于TensorFlow实现，参考：https://github.com/tensorflow/ranking

利用lightgbm做learning to rank 排序 : https://github.com/jiangnanboy/learning_to_rank 



