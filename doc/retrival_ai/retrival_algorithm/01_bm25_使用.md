# 文本相似度计算

## 一. 场景


业务拥有一批标准的公司名称数据，包括道琼斯名称，别名，原文名称等字段，预期诉求是产品可以提供如下能力：
- 当客户或供应商输入与标准数据相同的名称时(包括别名，简写，原名称), 文本相似度可判断为1.0
- 当客户或供应商输入与标准数据相近的名称时，文本相似度判断结果的值域为[0, 1）

详细请参考下图：

![image](https://github.com/ww5365/tiny_util/assets/15375027/62684328-b3ff-4d2e-bda5-b76f04ba8502)


## 二. 问题抽象和计算方法设计

产品诉求的本质是计算两个短文本之间的文本相似度，特殊的地方是业务拥有多个标准数据字段供使用，只需命中其中任一字段就，即相似性最高的作为最终的结果。

### 2.1 常用相似度计算方法

|  **方法** | **说明**  | **优势**  | **劣势**  |
| ------------ | ------------ | ------------ | ------------ |
| 基于词表  | 创建同义词/缩写/别名等词表进行映射  | 简单<br> 规则明确，可控  | 手工维护成本<br> 准确率依赖词表质量和覆盖  |
|  基于字符串相似度 | 计算文本间的编辑距离,LCS等  | 结果较可控  |  顺序敏感 |
|  基于统计规则 | 基于词频，词权重，BM25等  | 实现简单<br> 可解释性强  | 无法捕捉语义信息  |
|  基于词向量相似度 | 通过fastText或LLM模型向量化计算语义相似度  | 捕捉语义信息<br> 别名同义纠错都能支持  | 结果不可控<br> 资源和上线成本高  |
|   |   |   |   |

### 2.2 结合产品场景的计算方法设计

#### 约束条件
1. 支持对别名简称等的相似度计算,词表可以提供，参见上图中的多个"标注数据"字段
2. 可以对顺序不敏感，比如：Bank BPS 和 BPS-Bank 相同

基于约束条件和成本考虑，主要使用词表和统计规则算法，来设计实现文本相似度的计算。其中统计规则算法采用BM25算法来实现，具体算法过程参考下文的设计。

#### 计算方法设计

```
1. 核心算法是基于统计，特殊场景的case，基于词表进行调整。
2. 基于统计的核心算法：
	a. 使用多个标注数据字段的整体作为doc字段，统计词频
	b. 分别计算客户输入(记为query)和多个标注数据字段(记为doc1,doc2..)的bm25值
	c. 计算：std::min(query, doc1)/std::max(query, doc1) 记为s1，相似度比例值；其它字段类同。
    d. 取相似度最大值：std::max(s1,s2,…)  作为最终的similarity
```

### 三. 计算方法实现

#### 3.1 核心算法

Score = 

$$
Bm25\_Score = \sum_{i=1}^{n} IDF(q_i)\times TF(q_i)
$$

其中
$$
IDF(q_i)=ln(\frac{N-n(q_i)+0.5}{n(q_i)+0.5}+1)
$$
$N$为所有查询的文档数量，$n(q_i)$为含有$q_i$的文档数量
$$
TF(q_i)=\frac{f(q_i,D)\cdot(1 + k_1)}{f(q_i,D)+k_1\cdot(1-b+b\cdot\frac{|D|}{avgdl})} \cdot\frac{f(q_i, Q)\cdot(1+k_2)}{f(q_i, Q) + k_2}
$$

其中$f(q_i,D)$为$q_i$在文档出现的次数,$|D|$为查询的字段的单词长度，$avgdl$为所有查询文档中该字段的平均长度， $f(q_i,Q)$为$q_i$在query出现的次数,默认$k_1=1.2,b=0.75,k_2=1$。

#### 3.2 实现流程

![image](https://github.com/ww5365/tiny_util/assets/15375027/d9b24852-2e95-4be2-ad0f-683464227279)


#### 3.2 关键代码


``` python 
class BM25_Model(object):
    def __init__(self, documents_list, k1=1.2, k2=1, b=0.75):
        self.documents_list = documents_list
        self.documents_number = len(documents_list)
        self.avg_documents_len = sum([len(document) for document in documents_list]) / self.documents_number
        self.f = []
        self.idf = {}
        self.k1 = k1
        self.k2 = k2
        self.b = b
        self.init()
 
    def init(self):
        df = {}
        for document in self.documents_list:
            temp = {}
            for word in document:
                temp[word] = temp.get(word, 0) + 1
            self.f.append(temp) #每篇文档的每个term的频次统计 [{"term1" : 4},...]
            for key in temp.keys():
                df[key] = df.get(key, 0) + 1  #term出现在某个docs中,文档的数量
        for key, value in df.items():
            self.idf[key] = np.log((self.documents_number - value + 0.5) / (value + 0.5))
 
    def get_score(self, index, query):
        score = 0.0
        document_len = len(self.documents_list[index]) #  当前文档长度
        qf = Counter(query)
        for q in query:
            if q not in self.f[index]:
                continue
            score += self.idf[q] * (self.f[index][q] * (self.k1 + 1) / (
                        self.f[index][q] + self.k1 * (1 - self.b + self.b * document_len / self.avg_documents_len))) * (
                                 qf[q] * (self.k2 + 1) / (qf[q] + self.k2))
        return scor

```

### 四. 效果评估

通过人工抽检，计算得到相似度和人工标注相似度，控制误差在[-0.05, +0.05]，抽检准确率为90%。展示示例如下：

![image](https://github.com/ww5365/tiny_util/assets/15375027/410e084f-bb5a-4974-9cf4-0f45cfbac193)

