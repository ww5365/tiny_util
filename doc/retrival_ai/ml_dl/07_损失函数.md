# 损失函数


## CrossEntropyLoss

交叉熵损失: 用来描述两个概率分布p,q的距离，交叉熵值越小，说明两个概率分布越接近，距离越近。主要两种实现方式：

$$CE(y,\widehat{y}) = -{\frac{1}{N}}\sum_{i=0}^N({y_ilog({\widehat{y_i}}) + (1-y_i)log(1-\widehat{y_i})})$$




## MultipleNegativesRankingLoss



