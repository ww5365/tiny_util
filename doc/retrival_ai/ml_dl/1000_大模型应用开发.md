# 大模型应用开发

## 第二节

 * 解决chatgpt调用的API KEY的问题  
   chatgpt 的 api key 获取参考：  
   https://blog.csdn.net/ggw15938357681/article/details/136868911  
   https://github.com/chatanywhere/GPT_API_free?tab=readme-ov-file   
   授权成功:  您的免费API Key为: sk-8OI2yzDvjs4HDDu4JJGWzEYw1NQJC3eNTll8xW5Afuzwr9GR

   代码层面验证？参考这个chatanywhere项目中的demo.py调通chatgpt的接口  
   [代码](https://github.com/ww5365/python/blob/master/tanxin/src/llm_app_dev/openai_demo.p，y)
   本机：关闭代理设置   家机：按照说明跑

## 第三节

## 补充课： gradio

### gradio quick start


- 直观感受  
  使用了gradio, 比较受关注的项目:
  - [ChatGLM2-6b] (https://github.com/THUDM/chatGLM2-6B)
  - [**gpt_academic**] (https://github.com/binary-husky/gpt_academic?tab=readme-ov-file)
 
    
- 安装  
gradio安装： pip3 install gradio      python版本>=3.8
查看版本：pip3 show  gradio

- quick start  
quickstart官方参考 [参考](https://www.gradio.app/guides/quickstart)
  - 第一个demo  
    参考代码：[链接](https://github.com/ww5365/python/blob/master/tanxin/src/llm_app_dev/03_gradio_demo.py)
    ![image](https://github.com/ww5365/tiny_util/assets/15375027/932f19fc-2f10-49fc-97a6-65c4d5169fed)

- 演示MyGpt项目代码
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      
**todo: 总结**
- 这个MyGpt项目，是一个智能问答的较好的示例前端demo项目，可以用来参考。
- gpt_academic ： 这个项目可以尝试使用下，写论文
  

## 第四节


- llm 商业化落地的挑战
   - 效果
   - 隐私
   - 幻觉
   - ...
 
- 生成与检索
RAG ： Retrival Augmented Generation

比较了生成和检索的优缺点  
关键不同点：可控性

场景：金融智能客服系统

FAQ： <A, Q>  库

检索怎么和大模型结合？

主要思路是：Query 和 召回的每条结果，以及历史信息来构造大模型的prompt输入

1). query： 作为prompt的input  
2). 召回的每条结果item: 作为prompt的context   
3). 历史信息：作为prompt的message  

![](https://github.com/ww5365/tiny_util/assets/15375027/06942325-1e1f-4e43-9b82-a38d88be2c23)

**Todo：疑问**
但这样做的目的是什么呢？
RAG，利用大模型对召回的结果进行相关性判断？？进而进行排序？？

- 文本的向量化

  向量数据库：  drant    (approximate search)



## 第五节

接上节课， 进阶的RAG，   其实没说有意义的进阶的RAG， 后续有推荐系统的示例？？

上节课，还提供了，什么代码？ python app.py   PDF GPT    app.py db_qdrant.py  file_processor.py file_processor_helper.py AssistantGPT.py



  

  
  





















   


