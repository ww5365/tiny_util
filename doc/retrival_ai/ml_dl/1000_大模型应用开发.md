# 大模型应用开发

## 第二节

 * 解决chatgpt调用的API KEY的问题  
   chatgpt 的 api key 获取参考：  
   https://blog.csdn.net/ggw15938357681/article/details/136868911  
   https://github.com/chatanywhere/GPT_API_free?tab=readme-ov-file   
   授权成功:  您的免费API Key为: sk-8OI2yzDvjs4HDDu4JJGWzEYw1NQJC3eNTll8xW5Afuzwr9GR

   代码层面验证？参考这个chatanywhere项目中的demo.py调通chatgpt的接口  
   [代码](https://github.com/ww5365/python/blob/master/tanxin/src/llm_app_dev/openai_demo.p，y)
   本机：关闭代理设置   家机：按照说明跑

## 第三节

## 补充课： gradio

### gradio quick start


- 直观感受  
  使用了gradio, 比较受关注的项目:
  - [ChatGLM2-6b] (https://github.com/THUDM/chatGLM2-6B)
  - [**gpt_academic**] (https://github.com/binary-husky/gpt_academic?tab=readme-ov-file)
 
    
- 安装  
gradio安装： pip3 install gradio      python版本>=3.8
查看版本：pip3 show  gradio

- quick start  
quickstart官方参考 [参考](https://www.gradio.app/guides/quickstart)
  - 第一个demo  
    参考代码：[链接](https://github.com/ww5365/python/blob/master/tanxin/src/llm_app_dev/03_gradio_demo.py)
    ![image](https://github.com/ww5365/tiny_util/assets/15375027/932f19fc-2f10-49fc-97a6-65c4d5169fed)

- 演示MyGpt项目代码                                                                                                                                                                                                                                                                                                                                                                                                                         
**todo: 总结**
- 这个MyGpt项目，是一个智能问答的较好的示例前端demo项目，可以用来参考。
- gpt_academic ： 这个项目可以尝试使用下，写论文
  

## 第四节


- llm 商业化落地的挑战
   - 效果
   - 隐私
   - 幻觉
   - ...
 
- 生成与检索
RAG ： Retrival Augmented Generation

比较了生成和检索的优缺点  
关键不同点：可控性

场景：金融智能客服系统

FAQ： <A, Q>  库

检索怎么和大模型结合？

主要思路是：Query 和 召回的每条结果，以及历史信息来构造大模型的prompt输入

1). query： 作为prompt的input  
2). 召回的每条结果item: 作为prompt的context   
3). 历史信息：作为prompt的message  

![](https://github.com/ww5365/tiny_util/assets/15375027/06942325-1e1f-4e43-9b82-a38d88be2c23)

**Todo：疑问**
但这样做的目的是什么呢？
RAG，利用大模型对召回的结果进行相关性判断？？进而进行排序？？

- 文本的向量化

  向量数据库：  drant    (approximate search)



## 第五节

接上节课， 进阶的RAG，   其实没说有意义的进阶的RAG， 后续有推荐系统的示例？？

上节课，还提供了，什么代码？ python app.py   PDF GPT    app.py db_qdrant.py  file_processor.py file_processor_helper.py AssistantGPT.py



## 第六节

KNN
ANN
NSW
HNSW ： NSW + skip list   skip list ： 如何构造？

HSNW + ANN：

<img width="1222" alt="image" src="https://github.com/user-attachments/assets/42835ef5-0128-467a-89bc-f48fc0940c13">


### 传统推荐系统

基于内容的推荐 ： 
基于协同过滤的推荐

关键是了解推荐系统 如何与  大模型 结合使用？

MIND 数据集： https://msnews.github.io/   MIND-small


LLM for ranking：

构造prompt包含的核心要素： 1. query/ profile (context)  2. history(context)  3. recall (可以作为input)   



## 第七节

官方文档：
https://python.langchain.com/v0.1/docs/modules/model_io/prompts/few_shot_examples_chat/

## 第九节

RAG


多路召回： 混排 ： ensemble retriever

混排参考论文：https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf    思路还是很简单

评估: RAG 的评估开源框架 ： RAGAS

https://docs.ragas.io/en/latest/concepts/metrics/context_recall.html
  
## 第十一节




## 第十二节

huggingGPT：https://github.com/microsoft/JARVIS

这个网站，有很多开源的大模型，可以直接调用API：https://replicate.com/home


斯坦福小镇，多智能体设计：
    property
    memory
    planning
    react


Communicative Agents for Software Development
https://github.com/OpenBMB/ChatDev


function call : https://platform.openai.com/docs/guides/function-calling

## 第十四节


llma： https://github.com/meta-llama/llama

微调数据：？ self-instruction


## 第十五节


mistral-7b 模型训练：示例 ： https://colab.research.google.com/drive/1TVEd2fj3YiklvX5zOqJxQAmXnLOk6-to?usp=sharing#scrollTo=DhtO5dMr9Gq3

下面是简单记录了示例的note

里面用：QLora 降低显存的消耗

float16--》 4bit
1. float16 --》（0,1,2,3,4...15）
2. float16 --》（-7,-6...7,8）


``` python

model_id = "mistralai/Mistral-7B-v0.1"  # 模型的id：使用的是huggingface中的路径
model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={"":0}) # causal : decoder类的模型？
tokenizer = AutoTokenizer.from_pretrained(model_id, add_eos_token=True)   
tokenizer.padding_side = 'left'

# minibatch 时打平长度的方式，左填充
# sample1: I like this movie
# sample2: [pad] [pad] i like

```

``` python
from datasets import load_dataset
data = load_dataset("gbharti/finance-alpaca", split='train')
# gbharti/finance-alpaca  也是huggingface上的数据集,直接查询可以获取

# Explore the data
df = data.to_pandas()
df.head(10)
```

``` json
示例数据： gbharti/finance-alpaca

[
  {
    "instruction": "For a car, what scams can be plotted with 0% financing vs rebate?",
    "input": "",
    "output": "The car deal makes money 3 ways. If you pay in one lump payment. If the payment is greater than what they paid for the car, plus their expenses, they make a profit. They loan you the money. You make payments over months or years, if the total amount you pay is greater than what they paid for the car, plus their expenses, plus their finance expenses they make money. Of course the money takes years to come in, or they sell your loan to another business to get the money faster but in a smaller amount. You trade in a car and they sell it at a profit. Of course that new transaction could be a lump sum or a loan on the used car... They or course make money if you bring the car back for maintenance, or you buy lots of expensive dealer options. Some dealers wave two deals in front of you: get a 0% interest loan. These tend to be shorter 12 months vs 36,48,60 or even 72 months. The shorter length makes it harder for many to afford. If you can't swing the 12 large payments they offer you at x% loan for y years that keeps the payments in your budget. pay cash and get a rebate. If you take the rebate you can't get the 0% loan. If you take the 0% loan you can't get the rebate. The price you negotiate minus the rebate is enough to make a profit. The key is not letting them know which offer you are interested in. Don't even mention a trade in until the price of the new car has been finalized. Otherwise they will adjust the price, rebate, interest rate, length of loan,  and trade-in value to maximize their profit. The suggestion of running the numbers through a spreadsheet is a good one. If you get a loan for 2% from your bank/credit union for 3 years and the rebate from the dealer, it will cost less in total than the 0% loan from the dealer. The key is to get the loan approved by the bank/credit union before meeting with the dealer. The money from the bank looks like cash to the dealer.",
    "text": ""
  },
  {
    "instruction": "Why does it matter if a Central Bank has a negative rather than 0% interest rate?",
    "input": "",
    "output": "That is kind of the point, one of the hopes is that it incentivizes banks to stop storing money and start injecting it into the economy themselves. Compared to the European Central Bank investing directly into the economy the way the US central bank has been doing. (The Federal Reserve buying mortgage backed securities) On a country level, individual European countries have tried this before in recent times with no noticeable effect.",
    "text": ""
  }]

```


``` python
# 结论： Lora的应用可以发生在模型里面的任何线性转换上
# h=Wx  线性变换
# h = (W + \delta W) x

import bitsandbytes as bnb
def find_all_linear_names(model):
  cls = bnb.nn.Linear4bit #if args.bits == 4 else (bnb.nn.Linear8bitLt if args.bits == 8 else torch.nn.Linear)
  lora_module_names = set()
  for name, module in model.named_modules():
    if isinstance(module, cls):
      names = name.split('.')
      lora_module_names.add(names[0] if len(names) == 1 else names[-1])
    if 'lm_head' in lora_module_names: # needed for 16-bit
      lora_module_names.remove('lm_head')
  return list(lora_module_names)

```


``` python
from peft import LoraConfig, get_peft_model

lora_config = LoraConfig(
    r=8,  # lora rank r一般取值：8或16
    lora_alpha=32,  # new W = old W + loar_alpha/r * \delta_W    意义： 改动的W(\delta_W) 对整个W的影响大小
    target_modules=modules,  # qkv矩阵中，哪些参数进行微调
    lora_dropout=0.05,  # 防止过拟合 
    bias="none",  # 
    task_type="CAUSAL_LM"  # decoder类型的llm，不断的输出下一个单词
)

model = get_peft_model(model, lora_config)  # peft: prameters efficient fine tune   model  已经准备好使用loRa进行微调了

```

lora的方式训练：可以知道需要被微调的参数的占比？
trainable, total = model.get_nb_trainable_parameters()


```python
# 训练

```


``` python

import torch
from peft import PeftModel, PeftConfig
from transformers import AutoModelForCausalLM, AutoTokenizer

peft_model_id = "Ronal999/mistral_b_finance_finetuned_test"   ## 训练好的模型，并上传到huggingface的hub上的模型 仅包含\delta_W 部分
config = PeftConfig.from_pretrained(peft_model_id)  
model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, return_dict=True, load_in_4bit=True, device_map='auto')
tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)

# Load the Lora model
model = PeftModel.from_pretrained(model, peft_model_id)  ## model是基础模型的W部分，peft_model_id是\delta_W 部分

```

LLM factory :   web ui 方式，可以通过点点点的方式，进行模型的微调




### 补充：chatGLM 推理


github代码仓： https://github.com/THUDM/ChatGLM3/tree/main?tab=readme-ov-file

BBH： 评测集
该数据集由Google、斯坦福等研究人员开发，BBH的全称是BIG-Bench Hard，它是BIG-Bench数据集的一个子集，它专注于23个具有挑战性的任务，这些任务超出了当前语言模型的能力范围。BBH中的任务需要进行多步骤推理 ： https://paperswithcode.com/dataset/bbh 
看到这个数据集的样子：？
![image](https://github.com/user-attachments/assets/2d448198-a7db-4be4-93a0-c9af9c9418e1)


window 安装大模型 chatglm.cpp：
https://shanhai.huawei.com/#/page-forum/post-details?postId=83982

参考了这篇文件，在Ubuntu的云主机安装。































   


